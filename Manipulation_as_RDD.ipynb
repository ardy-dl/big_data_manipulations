{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI5QOY4ZeZze10J1mV2i2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ardy-dl/big_data_manipulations/blob/main/Manipulation_as_RDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext(appName=\"performanceFactors\")\n",
        "factorsrdd = sc.textFile(\"/content/StudentPerformanceFactors.csv\")"
      ],
      "metadata": {
        "id": "M1wUAH2RyB1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2282126c-69bf-4c62-f983-feb3ea53395e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=d7d226a6a5eb3318df51d5f27b235aa31683e036739b7d67899f174ce9fcf049\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "header = factorsrdd.first()  # header\n",
        "datardd = factorsrdd.filter(lambda row: row != header).map(lambda line: line.split(\",\"))  # rdd\n",
        "\n",
        "column_names = header.split(\",\")  # split headers\n",
        "column_index = {column_names[i].strip(): i for i in range(len(column_names))}  # dictionary for each column\n",
        "\n",
        "# index of specific columns\n",
        "exam_score_column = column_index['Exam_Score']\n",
        "previous_exam_column = column_index['Previous_Scores']\n",
        "sleep_column = column_index['Sleep_Hours']\n",
        "hrs_studied_column = column_index['Hours_Studied']\n",
        "income_column = column_index['Family_Income']\n",
        "Access_to_Resources = column_index['Access_to_Resources']\n",
        "Teacher_column = column_index['Teacher_Quality']\n",
        "School_Type = column_index['School_Type']\n",
        "Home_Column = column_index['Distance_from_Home']\n",
        "Attendance_column = column_index[\"Attendance\"]\n",
        "\n",
        "# Filter students who passed both exams\n",
        "passed_both_filtered = datardd.filter(lambda row: (\n",
        "    int(row[previous_exam_column].strip()) >= 70 and\n",
        "    int(row[exam_score_column].strip()) >= 70\n",
        "))\n",
        "\n",
        "# Filter students who passed the previous exam but not the recent one\n",
        "passed_previous_filtered = datardd.filter(lambda row: (\n",
        "    int(row[previous_exam_column].strip()) >= 70 and\n",
        "    int(row[exam_score_column].strip()) < 70\n",
        "))\n",
        "\n",
        "# Combine selected columns\n",
        "both_exam = passed_both_filtered.map(lambda row: (\n",
        "    int(row[hrs_studied_column].strip()),\n",
        "    (int(row[previous_exam_column].strip()),\n",
        "     row[income_column].strip(),\n",
        "     row[sleep_column].strip() + \" hrs\",\n",
        "     int(row[exam_score_column].strip()))\n",
        "))\n",
        "\n",
        "previous_exam = passed_previous_filtered.map(lambda row: (\n",
        "    row[income_column].strip(),\n",
        "    (int(row[previous_exam_column].strip()),\n",
        "     int(row[hrs_studied_column].strip()),\n",
        "     row[sleep_column].strip() + \" hrs\",\n",
        "     int(row[exam_score_column].strip()))\n",
        "))\n",
        "\n",
        "# Group by Family Income and sort by Previous Exam Score within each group\n",
        "groupby_income = previous_exam.groupByKey()\n",
        "sortedby_income = groupby_income.mapValues(lambda records: sorted(records, key=lambda x: x[1]))\n",
        "\n",
        "# Collect and print the results\n",
        "groupsorted_data = sortedby_income.collect()\n",
        "\n",
        "#for group_income, records in groupsorted_data:\n",
        "#    print(\"Family Income: \", group_income)\n",
        "#    for record in records:\n",
        "#        print(f\"  Hours_Studied: {record[1]}, Previous_Score: {record[0]}, Sleep_Hours: {record[2]}, Recent_Exam_Score: {record[3]}\")\n"
      ],
      "metadata": {
        "id": "3n6Kq9spzN1I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MenuQdAr8S2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "zgEoFxfs6AsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import col, when, count\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Student Performance\").getOrCreate()\n",
        "\n",
        "df = datardd.map(lambda row: Row(\n",
        "    Hours_Studied=int(row[hrs_studied_column].strip()),\n",
        "    Previous_Scores=int(row[previous_exam_column].strip()),\n",
        "    Family_Income=row[income_column].strip(),\n",
        "    Sleep_Hours=int(row[sleep_column].strip()),\n",
        "    Exam_Score=int(row[exam_score_column].strip()),\n",
        "    Resources=row[Access_to_Resources].strip(),\n",
        "    Teacher_Quality=row[Teacher_column].strip(),\n",
        "    School_Type=row[School_Type].strip(),\n",
        "    Home_Distance=row[Home_Column].strip(),\n",
        "    Attendance=row[Attendance_column].strip()\n",
        ")).toDF()\n",
        "\n",
        "# select\n",
        "selected_df = df.select(\"Hours_Studied\", \"Previous_Scores\", \"Family_Income\", \"Sleep_Hours\", \"Exam_Score\", \"Resources\", \"Teacher_Quality\", \"School_Type\")\n",
        "# filter\n",
        "filtered_df = selected_df.filter(selected_df[\"Previous_Scores\"] >= 70)\n",
        "\n",
        "# adding score range\n",
        "score_range_df = filtered_df.withColumn(\n",
        "    \"Score_Range\",\n",
        "    when((col(\"Previous_Scores\") >= 90), \"Line of 9 and above\")\n",
        "    .when((col(\"Previous_Scores\") >= 80) & (col(\"Previous_Scores\") < 90), \"Line of 8\")\n",
        "    .when((col(\"Previous_Scores\") >= 70) & (col(\"Previous_Scores\") < 80), \"Line of 7\")\n",
        ")\n",
        "\n",
        "grouped_score_income_df = score_range_df.groupBy(\"Resources\", \"Score_Range\").agg(count(\"*\").alias(\"Total_Students\"))\n",
        "\n",
        "# final results\n",
        "grouped_score_income_df.orderBy(\"Resources\", \"Score_Range\").show()"
      ],
      "metadata": {
        "id": "kyQk41er6O_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01b0854-0d15-4c79-e7fb-415f898d6681"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+--------------+\n",
            "|Resources|        Score_Range|Total_Students|\n",
            "+---------+-------------------+--------------+\n",
            "|     High|          Line of 7|           395|\n",
            "|     High|          Line of 8|           412|\n",
            "|     High|Line of 9 and above|           427|\n",
            "|      Low|          Line of 7|           271|\n",
            "|      Low|          Line of 8|           258|\n",
            "|      Low|Line of 9 and above|           243|\n",
            "|   Medium|          Line of 7|           660|\n",
            "|   Medium|          Line of 8|           654|\n",
            "|   Medium|Line of 9 and above|           721|\n",
            "+---------+-------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"student_performance\")\n",
        "# Is there a difference in exam scores between students from private and public?\n",
        "query = '''SELECT School_Type, COUNT(*) AS Total_Passed, AVG(Exam_Score) AS Avg_Exam_Score\n",
        "           FROM student_performance\n",
        "           WHERE Exam_Score >= 70\n",
        "           GROUP BY School_Type\n",
        "           ORDER BY Avg_Exam_Score DESC\n",
        "           '''\n",
        "schoolType = spark.sql(query)\n",
        "schoolType.show()\n",
        "\n",
        "# Does distance from home affects attendance and exam performance?\n",
        "df.createOrReplaceTempView(\"student_performance\")\n",
        "query = \"\"\"SELECT Home_Distance, AVG(Attendance) AS Avg_Attendance, AVG(Exam_Score) AS Avg_Exam_Score\n",
        "           FROM student_performance\n",
        "           GROUP BY Home_Distance\n",
        "           ORDER BY Avg_Exam_Score DESC\n",
        "           \"\"\"\n",
        "result = spark.sql(query)\n",
        "result.show()\n",
        "\n",
        "# Is there a threshold for Hours Studying in a week and Hours of Sleep per day after which further studying has diminishing returns on Exam Scores?\n",
        "df.createOrReplaceTempView(\"student_performance\")\n",
        "query = '''SELECT\n",
        "        CASE\n",
        "            WHEN Hours_Studied BETWEEN 0 and 5 THEN '0-5 Hours'\n",
        "            WHEN Hours_Studied BETWEEN 6 and 10 THEN '6-10 Hours'\n",
        "            WHEN Hours_Studied BETWEEN 11 and 15 THEN '11-15 Hours'\n",
        "            WHEN Hours_Studied BETWEEN 16 and 20 THEN '16-20 Hours'\n",
        "            ELSE '20+ Hours'\n",
        "        END AS Hours_Studied,\n",
        "\n",
        "        CASE\n",
        "            WHEN Sleep_Hours BETWEEN 0 AND 4 THEN '0-4 hours'\n",
        "            WHEN Sleep_Hours BETWEEN 5 AND 7 THEN '5-7 hours'\n",
        "            ELSE '8+ hours'\n",
        "        END AS Sleep_Hours,\n",
        "\n",
        "        AVG(Previous_Scores) AS Average_Previous_Scores\n",
        "\n",
        "        FROM student_performance\n",
        "        GROUP BY\n",
        "    CASE\n",
        "        WHEN Hours_Studied BETWEEN 0 AND 5 THEN '0-5 Hours'\n",
        "        WHEN Hours_Studied BETWEEN 6 AND 10 THEN '6-10 Hours'\n",
        "        WHEN Hours_Studied BETWEEN 11 AND 15 THEN '11-15 Hours'\n",
        "        WHEN Hours_Studied BETWEEN 16 AND 20 THEN '16-20 Hours'\n",
        "        ELSE '20+ Hours'\n",
        "    END,\n",
        "    CASE\n",
        "        WHEN Sleep_Hours BETWEEN 0 AND 4 THEN '0-4 hours'\n",
        "        WHEN Sleep_Hours BETWEEN 5 AND 7 THEN '5-7 hours'\n",
        "        ELSE '8+ hours'\n",
        "    END\n",
        "        ORDER BY Average_Previous_Scores DESC\n",
        "        '''\n",
        "result = spark.sql(query)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "cqn-P-13AM2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c1d3de-e773-40ea-cf92-38e8603bbe1f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------------+\n",
            "|School_Type|Total_Passed|   Avg_Exam_Score|\n",
            "+-----------+------------+-----------------+\n",
            "|     Public|        1122|71.99643493761141|\n",
            "|    Private|         503|71.98210735586481|\n",
            "+-----------+------------+-----------------+\n",
            "\n",
            "+-------------+-----------------+-----------------+\n",
            "|Home_Distance|   Avg_Attendance|   Avg_Exam_Score|\n",
            "+-------------+-----------------+-----------------+\n",
            "|         Near|80.16786817713697|67.51210092687951|\n",
            "|     Moderate|79.85435435435436|66.98148148148148|\n",
            "|          Far|79.43617021276596|66.45744680851064|\n",
            "|             |77.92537313432835|66.43283582089552|\n",
            "+-------------+-----------------+-----------------+\n",
            "\n",
            "+-------------+-----------+-----------------------+\n",
            "|Hours_Studied|Sleep_Hours|Average_Previous_Scores|\n",
            "+-------------+-----------+-----------------------+\n",
            "|   6-10 Hours|  5-7 hours|      77.54913294797687|\n",
            "|    20+ Hours|  0-4 hours|      76.95744680851064|\n",
            "|   6-10 Hours|  0-4 hours|      75.88888888888889|\n",
            "|    0-5 Hours|  5-7 hours|                75.5625|\n",
            "|    20+ Hours|   8+ hours|               75.40625|\n",
            "|  16-20 Hours|  5-7 hours|      75.30119453924915|\n",
            "|    20+ Hours|  5-7 hours|      75.09604519774011|\n",
            "|   6-10 Hours|   8+ hours|                   75.0|\n",
            "|  11-15 Hours|  5-7 hours|      74.96842105263158|\n",
            "|  16-20 Hours|   8+ hours|      74.71739130434783|\n",
            "|  11-15 Hours|  0-4 hours|      74.65573770491804|\n",
            "|    0-5 Hours|  0-4 hours|                   74.5|\n",
            "|  16-20 Hours|  0-4 hours|      73.69411764705882|\n",
            "|  11-15 Hours|   8+ hours|      73.02173913043478|\n",
            "|    0-5 Hours|   8+ hours|      71.47826086956522|\n",
            "+-------------+-----------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ayK8Bl3f1sI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}